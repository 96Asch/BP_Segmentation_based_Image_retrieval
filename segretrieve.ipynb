{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Content Based Image Retrieval through Image Segmentation\n",
    "\n",
    "This demo will take a user given image, segment it and compare the results of the Content Based Image Retrieval system using the original and the segmented image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "We prepare the dataset used for this research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root = os.path.abspath(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO\n",
    "\n",
    "We will use the COCO validation dataset and use the cocoapi to extract information from the annotations.\n",
    "Download the images from the [COCO](http://cocodataset.org/#download) website and extract it to the datasets folder.\n",
    "Then at the cocoapi [repo](https://github.com/philferriere/cocoapi), follow the installation instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"models\"\n",
    "DATASET_FOLDER = \"datasets\"\n",
    "FEATURES_FOLDER = \"features\"\n",
    "\n",
    "SUBSET = 'val'\n",
    "YEAR = '2017'\n",
    "\n",
    "TEMP_DIR = \"temp\"\n",
    "\n",
    "RESIZED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/asch/.local/share/virtualenvs/Bachelor_Project-OOisEnRi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use images in datasets/val2017\n",
      "Will use annotations in datasets/annotations/instances_val2017.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(root, \"cocoapi/\"))\n",
    "from pycocotools.coco import COCO\n",
    "import coco\n",
    "\n",
    "# initialize COCO api for instance annotations\n",
    "dataset = coco.CocoDataset()\n",
    "coco_dat = dataset.load_coco(dataset_dir=DATASET_FOLDER, subset=SUBSET, year=YEAR, return_coco=True, auto_download=True)\n",
    "dataset.prepare() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Database\n",
    "The features are stored in a hd5f database which allows for easy search and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features to features/val2017.hdf5\n"
     ]
    }
   ],
   "source": [
    "from utils import Database\n",
    "\n",
    "RESIZE = 299\n",
    "FEATURES_DB = '{0}/{1}{2}.hdf5'.format(FEATURES_FOLDER, SUBSET, YEAR)\n",
    "print('Saving features to {}'.format(FEATURES_DB))\n",
    "\n",
    "database = Database(FEATURES_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving images from datasets/val2017\n",
      "Creating dataset from 5000 images\n",
      "Database exists at features/val2017.hdf5\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "\n",
    "\n",
    "image_dir = \"{0}/{1}{2}\".format(DATASET_FOLDER, SUBSET, YEAR)\n",
    "print(\"Retrieving images from {}\".format(image_dir))\n",
    "\n",
    "IMAGES = []\n",
    "for image_format in [\"jpg\"]:\n",
    "    IMAGES += glob.glob(\"{}/*.{}\".format(image_dir, image_format))\n",
    "print(\"Creating dataset from {} images\".format(len(IMAGES)))\n",
    "IMAGES.sort()\n",
    "\n",
    "database.create(FEATURES_DB, IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "Extract the image features from the dataset using a pretrained model (vgg16, vgg19, inception or resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Patterns\n",
    "Local Binary Patterns are used to detect intensity changes over an image. This can then be used to detect textural features of an image. Here we use an extension to the Local Binary Patterns where we use a number of points P and a radius R to calculate the LBP value of a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lbp already exists in features/val2017.hdf5\n"
     ]
    }
   ],
   "source": [
    "from utils import LocalBinaryPatterns\n",
    "\n",
    "lbp = LocalBinaryPatterns(num_processes=8, temp_dir=TEMP_DIR, hdf5_path=FEATURES_DB, num_points=24, radius=3, eps=1e-7)\n",
    "lbp.dump(image_paths=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset color already exists in features/val2017.hdf5\n"
     ]
    }
   ],
   "source": [
    "from utils import Color\n",
    "color = Color(num_processes=8, temp_dir=TEMP_DIR, hdf5_path=FEATURES_DB)\n",
    "color.dump(image_paths=IMAGES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coltex HSV Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned temp files in /home/asch/Documents/Bachelor_Project/temp\n",
      "[INFO] launching pool using 8 processes...\n",
      "[INFO] starting process 2[INFO] starting process 1[INFO] starting process 0[INFO] starting process 3[INFO] starting process 5[INFO] starting process 6[INFO] starting process 7[INFO] starting process 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 76, in describe\n",
      "    HORI[npiQi][qhQh] += wi_main + wh_diag\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 51, in describe\n",
      "    wh_hori, wi_hori = self.calculate_weight_hue(sat_hori, int_hori), self.calculate_weight_int(sat_hori, int_hori)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/feature.py\", line 48, in process\n",
      "    features[image_path] = self.get_feature(image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 50, in describe\n",
      "    wh_vert, wi_vert = self.calculate_weight_hue(sat_vert, int_vert), self.calculate_weight_int(sat_vert, int_vert)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 83, in get_feature\n",
      "    return self.describe(hsv_image)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 63, in describe\n",
      "    qhQh = math.ceil(hue_vert / self.quantization_hue)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 51, in describe\n",
      "    wh_hori, wi_hori = self.calculate_weight_hue(sat_hori, int_hori), self.calculate_weight_int(sat_hori, int_hori)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 23, in calculate_weight_int\n",
      "    return 1 - self.calculate_weight_hue(saturation, intensity)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 54, in describe\n",
      "    qhQh = math.ceil(hue_diag / self.quantization_hue)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 49, in describe\n",
      "    wh_diag, wi_diag = self.calculate_weight_hue(sat_diag, int_diag), self.calculate_weight_int(sat_diag, int_diag)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 48, in describe\n",
      "    wh_main, wi_main = self.calculate_weight_hue(sat_main, int_main), self.calculate_weight_int(sat_main, int_main)\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 20, in calculate_weight_hue\n",
      "    return saturation**(0.1 * ((255 / intensity) ** 0.85) )\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 17, in calculate_weight_hue\n",
      "    if intensity == 0:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 17, in calculate_weight_hue\n",
      "    if intensity == 0:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 20, in calculate_weight_hue\n",
      "    return saturation**(0.1 * ((255 / intensity) ** 0.85) )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/asch/Documents/Bachelor_Project/utils/coltex.py\", line 20, in calculate_weight_hue\n",
      "    return saturation**(0.1 * ((255 / intensity) ** 0.85) )\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e631ae0ea923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoltex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColtex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEMP_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdf5_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFEATURES_DB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_hue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcoltex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Bachelor_Project/utils/feature.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, image_paths)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] launching pool using {} processes...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayloads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] waiting for processes to finish...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import Coltex\n",
    "\n",
    "coltex = Coltex(num_processes=8, temp_dir=TEMP_DIR, hdf5_path=FEATURES_DB, quantization_hue=4, quantization_int=4)\n",
    "coltex.dump(image_paths=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFPcBuVFw61h"
   },
   "source": [
    "## 3. Image Segmentation\n",
    "\n",
    "This program will use Facebooks's [Mask-RCNN](https://github.com/matterport/Mask_RCNN) convolutional neural network, to segment a given image and give the bounding boxes of those segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "\n",
    "COCO_MODEL_PATH = '{}/{}'.format(MODEL_FOLDER, 'mask_rcnn_coco.h5')\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "print('Creating MaskRCNN object')\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_FOLDER, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "print('Loading weights from {}'.format(COCO_MODEL_PATH))\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a random image\n",
    "We select a random image from the dataset and use it to match against other images and also get the classes from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(image_path, coco_dat):\n",
    "    \"\"\"Retrieves the list of classes for a given image name from the COCO annotations.\n",
    "\n",
    "        Args:\n",
    "            image_path: The relative path to the image.\n",
    "\n",
    "        Returns:\n",
    "            2D array: Returns a list of classes in string format.\n",
    "    \"\"\"\n",
    "    image_id = get_image_id(image_path)\n",
    "    annid = coco_dat.getAnnIds(image_id)\n",
    "    ann = coco_dat.loadAnns(annid)\n",
    "    cats = [coco_dat.loadCats(ann[i]['category_id'])[0]['name'] for i in range(len(ann))]\n",
    "    return cats\n",
    "\n",
    "def get_image_id(image_path):\n",
    "    \"\"\"Retrieves the id for a given image name.\n",
    "\n",
    "        Args:\n",
    "            image_path: The relative path to the image.\n",
    "\n",
    "        Returns:\n",
    "            int: Returns the integer id of the given image.\n",
    "    \"\"\"\n",
    "    no_ext = os.path.splitext(image_path)[0]\n",
    "    base_id = no_ext.split('/')[-1]\n",
    "    return int(base_id.lstrip('0'))\n",
    "\n",
    "def score(query_id, retrieved_ids, coco_dat):\n",
    "    query_class = get_class(query_id, coco_dat)\n",
    "    retrieved_class = [get_class(retrieved_ids[i], coco_dat) for i in range(len(retrieved_ids))]\n",
    "    intersects = [len(np.intersect1d([query_class], retrieved_class[i])) for i in range(len(retrieved_ids))]\n",
    "    scores = [intersects[i] / min(len(query_class), max(1, len(retrieved_class[i]))) for i in range(len(retrieved_ids))]\n",
    "    final_score = np.sum(scores) / len(retrieved_ids) \n",
    "    return final_score, scores\n",
    "\n",
    "    \n",
    "def calc_precision_recall(query_id, retrieved_ids, coco_dat):\n",
    "    query_class = get_class(query_id, coco_dat)\n",
    "    retrieved_class = [get_class(retrieved_ids[i], coco_dat) for i in range(len(retrieved_ids))]\n",
    "    check = np.array([len(np.intersect1d([query_class], retrieved_class[i])) > 0 for i in range(len(retrieved_ids))])  \n",
    "    print(coco_dat.getCatIds(query_class[0]))\n",
    "    print(len(coco_dat.getImgIds(catIds=[39])))\n",
    "    class_max = [len(coco_dat.getImgIds(coco_dat.getCatIds(query_class[i]))) for i in range(len(query_class))]\n",
    "    print(check)\n",
    "    print(class_max)\n",
    "    tp = np.sum(check)\n",
    "    precision, recall = 0, 0\n",
    "    return precision, recall\n",
    "    \n",
    "\n",
    "\n",
    "NUM_RETRIEVE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "file_names = next(os.walk(DATASET_FOLDER + '/' + SUBSET + YEAR))[2]\n",
    "selected_image = random.choice(file_names)\n",
    "print(selected_image)\n",
    "print(get_class(selected_image,coco_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Mask-RCNN on the given image\n",
    "We read the randomly selected image and run the Mask-RCNN on the image to obtain the segments, masks and bounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_name = '{0}/{1}{2}/{3}'.format(DATASET_FOLDER, SUBSET, YEAR, selected_image)\n",
    "IMAGE = cv2.imread(rand_image_name)\n",
    "if RESIZED:\n",
    "    image = cv2.resize(IMAGE, (RESIZE, RESIZE))\n",
    "\n",
    "# Run detection\n",
    "print('Running inference on {}'.format(rand_image_name))\n",
    "results = model.detect([IMAGE])\n",
    "\n",
    "# Visualize results\n",
    "RESULT = results[0]\n",
    "visualize.display_instances(IMAGE[...,::-1], RESULT['rois'], RESULT['masks'], RESULT['class_ids'], \n",
    "                            dataset.class_names, RESULT['scores'], figsize=(8,8))\n",
    "\n",
    "CLASSES = [dataset.class_names[x] for x in RESULT['class_ids']]\n",
    "CLASSES.append(\"no class\")\n",
    "t = lbp.describe(IMAGE)\n",
    "print((t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVE_NUM = 200\n",
    "SHOW_NUM = 20\n",
    "\n",
    "IDS = database.read('id')\n",
    "base_image_index = np.where(IDS == rand_image_name)[0][0]\n",
    "\n",
    "# Remove the base image from all datasets\n",
    "IDS = np.delete(IDS, base_image_index, axis=0)\n",
    "\n",
    "LBP = database.read('lbp')\n",
    "LBP = np.delete(LBP, base_image_index, axis=0)\n",
    "\n",
    "COL = database.read('color_moments')\n",
    "COL = np.delete(COL, base_image_index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature Extraction on query image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Binary Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the Local Binary Pattern from the arbitrarily chosen image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from utils import visualize_histogram\n",
    "\n",
    "# Convert the RGB image into a Grayscaled image\n",
    "GRAY = cv2.cvtColor(IMAGE, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "original_lbp = lbp.describe(GRAY);\n",
    "visualize_histogram(original_lbp, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a pairwise Euclidean distance calculation of the LBP of the chosen image and the LBPs of all images in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_lbp = original_lbp[0].reshape(1, -1)\n",
    "distances_lbp = pairwise_distances(reshaped_lbp, LBP).ravel()\n",
    "\n",
    "distances_sorted_indices = distances_lbp.argsort()\n",
    "sorted_image_names = IDS[distances_sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show the first N retrieved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_images\n",
    "\n",
    "N = 5\n",
    "\n",
    "classes = [get_class(i, coco_dat) for i in sorted_image_names[:N]]\n",
    "sorted_images = [cv2.imread(i) for i in sorted_image_names[:N]]\n",
    "\n",
    "visualize_images(sorted_images, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV = cv2.cvtColor(IMAGE, cv2.COLOR_BGR2HSV)\n",
    "hsv = color.process_hsv(HSV)\n",
    "original_color = color.calc_moment(hsv)\n",
    "\n",
    "distances_color = pairwise_distances(original_color.reshape(1,-1), COL)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(HSV)\n",
    "fig.show()\n",
    "# indices_color = np.argsort(distances_color)[0][:RETRIEVE_NUM]\n",
    "\n",
    "# image_names_color = [IDS[index] for index in indices_color[:SHOW_NUM]]\n",
    "# images_color = [cv2.imread(IDS[index]) for index in indices_color[:SHOW_NUM]]\n",
    "# images_color = [cv2.resize(image, (200,200)) for image in images_color]\n",
    "\n",
    "# result = build_montages(images_color, (200, 200), (5,3))[0]\n",
    "# cv2.imshow(\"Result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[HSV histograms](https://www.researchgate.net/publication/4145416_Color-texture_feature_extraction_using_soft_decision_from_the_HSV_color_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Coltex\n",
    "\n",
    "coltex = Coltex(4, 4)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_distances(distances, weights):\n",
    "    combined = np.zeros(distances.shape[-2:])\n",
    "    for i in range(len(distances)):\n",
    "        combined += distances[i] * weights[i]\n",
    "    return combined\n",
    "\n",
    "distance_combined = combine_distances(np.array([distances_lbp, distances_color]), [0.5, 0.5])\n",
    "indices_combined = np.argsort(distance_combined)[0][:RETRIEVE_NUM]\n",
    "\n",
    "image_names_combined = [IDS[index] for index in indices_combined[:SHOW_NUM]]\n",
    "images_combined = [cv2.imread(IDS[index]) for index in indices_combined[:SHOW_NUM]]\n",
    "images_combined = [cv2.resize(image, (200,200)) for image in images_combined]\n",
    "\n",
    "# result = build_montages(images_combined, (200, 200), (5,3))[0]\n",
    "# cv2.imshow(\"Result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction on segmented query image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region(image, roi):\n",
    "    return image[roi[0]:roi[2], roi[1]:roi[3]]\n",
    "\n",
    "def join_features(features, weights):\n",
    "    combined = np.zeros(features.shape[1])\n",
    "    for i in range(features.shape[0]):\n",
    "        combined += np.multiply(features[i], weights[i])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the result of the inference, which provides us with the masks of all the segments and we create the segments from the base image. The last segmented image is the inverted combination of all masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIS = np.array(RESULT['rois'])\n",
    "ROIS = np.vstack([ROIS, [0, 0, IMAGE.shape[0], IMAGE.shape[1]]])\n",
    "NUM_SEGMENTS = ROIS.shape[0]\n",
    "print('Extracted {} segments'.format(NUM_SEGMENTS))\n",
    "\n",
    "# Retrieve the masks for all the segments from the MRCNN result.\n",
    "MASKS = np.array(RESULT['masks'])\n",
    "\n",
    "# Combine all masks to create a mask for the image without segments.\n",
    "COMBINED_MASK = np.zeros((MASKS.shape[:2]), dtype=bool)\n",
    "for i in range(MASKS.shape[2]):\n",
    "    COMBINED_MASK = np.logical_or(COMBINED_MASK, MASKS[:,:,i])\n",
    "COMBINED_MASK = ~COMBINED_MASK\n",
    "\n",
    "MASKS = np.dstack([MASKS, COMBINED_MASK])\n",
    "\n",
    "# Create segmented images from the masks.\n",
    "MASKED_IMAGES = []\n",
    "    \n",
    "for k in range(NUM_SEGMENTS):\n",
    "    mask = IMAGE.copy()\n",
    "    for i in range(IMAGE.shape[0]):\n",
    "        for j in range(IMAGE.shape[1]):\n",
    "            if MASKS[i, j, k] == False:\n",
    "               mask[i, j] = 0\n",
    "    MASKED_IMAGES.append(mask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REGION_WEIGHTS = [np.count_nonzero(MASKS[:,:,i]==0) / (IMAGE.shape[0] * IMAGE.shape[1]) for i in range(NUM_SEGMENTS)]\n",
    "# REGION_WEIGHTS[-1] *= np.sort(REGION_WEIGHTS)[-2]\n",
    "# REGION_WEIGHTS = np.divide(REGION_WEIGHTS, np.sum(REGION_WEIGHTS))\n",
    "# print(REGION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize the segmented image with the corresponding class of each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_images\n",
    "\n",
    "visualize_images(MASKED_IMAGES, CLASSES, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Local Binary Patterns we run the same algorithm as before to produce the LBP histograms of each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import visualize_histograms\n",
    "\n",
    "# For each of the images in the segmented image list, convert the image into grayscale\n",
    "gray_masked_segments = [cv2.cvtColor(MASKED_IMAGES[i], cv2.COLOR_BGR2GRAY) for i in range(NUM_SEGMENTS)]\n",
    "# Then extract the region using the bounding box of the segment.\n",
    "gray_masked_segments = [extract_region(gray_masked_segments[i], ROIS[i]) for i in range(NUM_SEGMENTS)]\n",
    "\n",
    "# Run the Local Binary Patterns algorithm on the grayscaled regions.\n",
    "lbp_segments = [lbp.describe(gray_masked_segments[i]) for i in range(NUM_SEGMENTS)]\n",
    "\n",
    "\n",
    "visualize_images(gray_masked_segments, CLASSES, fontsize=20, gray=True)\n",
    "visualize_histograms(lbp_segments, CLASSES, fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_ex_lbp = join_features(np.array(ex_lbp), REGION_WEIGHTS)\n",
    "\n",
    "# dists_ex_lbp = [pairwise_distances(ex_lbp[i].reshape(1,-1), LBP) for i in range(NUM_SEGMENTS)]\n",
    "\n",
    "# dists_ex_lbp_com = combine_distances(np.array(dists_ex_lbp), REGION_WEIGHTS)\n",
    "# dist_ex_lbp = pairwise_distances(result_ex_lbp.reshape(1,-1), LBP)\n",
    "\n",
    "# indices_ex_lbp = np.argsort(dist_ex_lbp)[0][:RETRIEVE_NUM]\n",
    "\n",
    "# images_ex_lbp = [cv2.imread(IDS[index]) for index in indices_ex_lbp]\n",
    "# images_ex_lbp = [cv2.resize(image, (200,200)) for image in images_ex_lbp]\n",
    "# image_names_ex_lbp = [IDS[index] for index in indices_ex_lbp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(MASKS[0].shape)\n",
    "ex_proc_hsv = [color.process_hsv(HSV, MASKS[:, :, i]) for i in range(NUM_SEGMENTS)]\n",
    "ex_color = [color.calc_moment(ex_proc_hsv[i]) for i in range(NUM_SEGMENTS)]\n",
    "result_ex_color = join_features(np.array(ex_color), REGION_WEIGHTS)\n",
    "\n",
    "dists_ex_color = [pairwise_distances(ex_color[i].reshape(1,-1), COL) for i in range(NUM_SEGMENTS)]\n",
    "\n",
    "dists_ex_color_com = combine_distances(np.array(dists_ex_color), REGION_WEIGHTS)\n",
    "dist_ex_color = pairwise_distances(result_ex_color.reshape(1,-1), COL)\n",
    "\n",
    "indices_ex_color = np.argsort(dists_ex_color_com)[0][:RETRIEVE_NUM]\n",
    "\n",
    "images_ex_color = [cv2.imread(IDS[index]) for index in indices_ex_color]\n",
    "images_ex_color = [cv2.resize(image, (200,200)) for image in images_ex_color]\n",
    "image_names_ex = [IDS[index] for index in indices_ex_color]\n",
    "\n",
    "# result = build_montages(images_ex_color, (200, 200), (5,3))[0]\n",
    "# cv2.imshow(\"Result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ex_combined = combine_distances(np.array([dist_ex_lbp, dist_ex_color]), [0.5, 0.5])\n",
    "indices_ex_combined = np.argsort(dist_ex_combined)[0][:RETRIEVE_NUM]\n",
    "\n",
    "image_names_ex_combined = [IDS[index] for index in indices_ex_combined[:SHOW_NUM]]\n",
    "images_ex_combined = [cv2.imread(IDS[index]) for index in indices_ex_combined[:SHOW_NUM]]\n",
    "images_ex_combined = [cv2.resize(image, (200,200)) for image in images_ex_combined]\n",
    "\n",
    "print(image_names_ex_combined[0])\n",
    "\n",
    "# result = build_montages(images_ex_combined, (200, 200), (5,3))[0]\n",
    "# cv2.imshow(\"Result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returned Images\n",
    "Here are the first N returned results of the unsegmented and segmented image resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We calculate the Recall and Precision for both the unsegmented and segmented retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we will assume that an image is correctly retrieved when it shares at least one class with the query image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_un_ids = [int(get_image_id(IDS[i])) for i in indices_combined[:NUM_RETRIEVE]]\n",
    "retrieved_un_ids[retrieved_un_ids == id] = int(get_image_id(IDS[indices_combined[NUM_RETRIEVE]]))\n",
    "\n",
    "# precision_un, recall_un = calc_precision_recall(id, retrieved_un_ids, coco_dat)\n",
    "un_score, un_scores = score(id, retrieved_un_ids, coco_dat)\n",
    "\n",
    "un_classes = [get_class(i, coco_dat) for i in retrieved_un_ids]\n",
    "\n",
    "# retrieved_un = [cv2.imread(IDS[index]) for index in retrieved_un_ids[:SHOW_NUM]]\n",
    "# retrieved_un = [cv2.resize(image, (200,200)) for image in retrieved_un]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_seg_ids = [int(get_image_id(IDS[i])) for i in indices_ex_combined[:NUM_RETRIEVE]]\n",
    "retrieved_seg_ids[retrieved_seg_ids == id] = int(get_image_id(IDS[indices_ex_combined[NUM_RETRIEVE]]))\n",
    "seg_score, seg_scores = score(id, retrieved_seg_ids, coco_dat)\n",
    "un_ex_classes = [get_class(i, coco_dat) for i in retrieved_seg_ids]\n",
    "\n",
    "# retrieved_seg = [cv2.imread(IDS[index]) for index in retrieved_seg_ids[:SHOW_NUM]]\n",
    "# retrieved_seg = [cv2.resize(image, (200,200)) for image in retrieved_seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score Unsegmented image: {}'.format(un_score))\n",
    "print('Score Segmented image: {}'.format(seg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IMAGE[...,::-1])\n",
    "original_classes = get_class(get_image_id(rand_image_name), coco_dat)\n",
    "plt.title(\", \".join(original_classes))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vis_cbir_results(IMAGE, images_combined, un_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_cbir_results(IMAGE, images_ex_combined, un_ex_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "DeepLab Demo.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Bachelor_Project",
   "language": "python",
   "name": "bachelor_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
